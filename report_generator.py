import json
import os
from openai import OpenAI
import os
from datetime import datetime

# Initialize OpenAI client (API key is automatically picked up from environment)
# We are configuring it to use the Gemini API via the OpenAI-compatible client
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
if GEMINI_API_KEY:
    client = OpenAI(
        api_key=GEMINI_API_KEY,
        base_url="https://api.gemini.com/v1/models" # Corrected base URL for Gemini API
    )
else:
    # Fallback to OpenAI if GEMINI_API_KEY is not set, but this will likely fail due to the previous 401 error
    client = OpenAI()

RAW_DATA_PATH = "raw_data/arxiv_raw_data.json"
REPORT_DIR = "reports"
os.makedirs(REPORT_DIR, exist_ok=True)

def load_raw_data():
    """Loads the raw data collected by the data_collector."""
    try:
        with open(RAW_DATA_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: Raw data file not found at {RAW_DATA_PATH}")
        return []
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from {RAW_DATA_PATH}")
        return []

def generate_summary(paper_data):
    """
    Uses the LLM to generate a concise, high-value summary of a single paper.
    """
    title = paper_data.get("title", "Unknown Title")
    url = paper_data.get("url", "No URL")
    
    # The prompt is crucial for high-quality, monetizable content
    prompt = f"""
    You are an expert AI Research Analyst. Your task is to analyze the following AI paper and generate a concise, high-value summary for a professional audience (VCs, AI Developers).

    The summary must be structured as follows:
    1. **Title:** The original title.
    2. **Source:** The source (e.g., arXiv).
    3. **Core Innovation:** A single sentence describing the main breakthrough or innovation.
    4. **Key Takeaways (Bullet Points):** 3-4 bullet points detailing the most important findings, benchmarks, or implications.
    5. **Link:** The original URL.

    Paper Details:
    Title: {title}
    URL: {url}
    
    Since we only have the title and URL, you must use your general knowledge to infer the content and provide a high-quality, speculative summary based on the title and the context of recent AI research. Focus on the potential impact and novelty.
    """
    
    try:
        response = client.chat.completions.create(
            model="gemini-2.5-flash", # Using the recommended fast and cost-effective model (Ensure the base_url is correct for this model)
            messages=[
                {"role": "system", "content": "You are an expert AI Research Analyst."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Error generating summary for '{title}': {e}")
        return f"Summary generation failed due to an API error: {e}"

def generate_full_report(summaries):
    """
    Compiles all individual summaries into a single, premium Markdown report.
    """
    report_date = datetime.now().strftime("%Y-%m-%d")
    report_title = f"Autonomous AI Research Briefing: {report_date}"
    
    report_content = f"""# {report_title}

**A Premium, AI-Curated Report on the Latest AI Model Updates and Benchmarks.**

This report was autonomously generated by the Autonomous Knowledge Broker (AKB) using the latest LLM technology to distill the most critical developments in AI research.

---

"""
    
    for i, summary in enumerate(summaries):
        report_content += f"## {i+1}. New Research Insight\n\n"
        report_content += summary
        report_content += "\n\n---\n\n"
        
    report_content += """
**Disclaimer:** This report is for informational purposes only. The content is generated by an AI agent and should be verified by a human expert before use in critical applications.

**Monetized via Paywen.dev**
"""
    
    file_name = f"ai_research_briefing_{report_date}.md"
    file_path = os.path.join(REPORT_DIR, file_name)
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
        
    print(f"Full premium report saved to {file_path}")
    return file_path

def main():
    raw_data = load_raw_data()
    if not raw_data:
        print("No raw data to process. Exiting report generator.")
        return None

    summaries = []
    for paper in raw_data:
        summary = generate_summary(paper)
        summaries.append(summary)
        
    if summaries:
        return generate_full_report(summaries)
    
    return None

if __name__ == "__main__":
    main()
